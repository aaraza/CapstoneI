{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be used when converted to real script to maintain ID ordering when we cluster and label \n",
    "# just need to change target table \n",
    "\n",
    "conn = psycopg2.connect(\"dbname='cap' user='postgres' host='ec2-34-215-56-46.us-west-2.compute.amazonaws.com' port=9000 password ='secret'\")\n",
    "data = pd.read_sql_query(\"SELECT * FROM nlp_dim_hpc ORDER BY id ASC\", conn)\n",
    "\n",
    "\n",
    "# going to try on a bunch of article bodies without NLP for performance\n",
    "# data = pd.read_sql_query(\"SELECT * FROM articles ORDER BY id ASC\", conn)\n",
    "\n",
    "# data = pd.read_csv('nlp_dim_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164541 entries, 0 to 164540\n",
      "Data columns (total 21 columns):\n",
      "index                 164541 non-null int64\n",
      "site                  164541 non-null object\n",
      "title                 164538 non-null object\n",
      "author                126494 non-null object\n",
      "published_on          130775 non-null object\n",
      "accessed_on           164541 non-null datetime64[ns]\n",
      "url                   164541 non-null object\n",
      "body                  164541 non-null object\n",
      "newspaper_keywords    164541 non-null object\n",
      "newspaper_summary     164541 non-null object\n",
      "id                    164541 non-null int64\n",
      "tokenized_body        164541 non-null object\n",
      "word_count            164541 non-null int64\n",
      "stopworded_body       164541 non-null object\n",
      "lemmatized_body       164541 non-null object\n",
      "word_bag              164541 non-null object\n",
      "named_entities        164541 non-null object\n",
      "lexical_diversity     164541 non-null float64\n",
      "sentiment_score       164541 non-null object\n",
      "binary_sentiment      164541 non-null int64\n",
      "cluster_label         164541 non-null int32\n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), int64(4), object(14)\n",
      "memory usage: 25.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# data.head()\n",
    "data.info()\n",
    "data.to_pickle('nlp_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/tf_vectorizer_obj.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "# transforms data into tfidf matrix representation\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=200,\n",
    "                                 min_df=2, use_idf=True)\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "\n",
    "joblib.dump(vectorizer, 'model/tf_vectorizer_obj.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<164541x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8159976 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit our data (list of article bodies) to a tfidf representation\n",
    "X = vectorizer.fit_transform(data.lemmatized_body)\n",
    "\n",
    "# verify we have a sparse matrix of 100 tfidf features for each article \n",
    "# should be 5*100 sparse matrix\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data that we have of TFIDF vectors into a file\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('model/tf_idf.npz', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<164541x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8159976 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sparse.load_npz('model/tf_idf.npz')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# How many clusters we want\n",
    "true_k = 15\n",
    "\n",
    "# create the KMeans object with initial settings\n",
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 201702.624\n",
      "Iteration  1, inertia 119662.967\n",
      "Iteration  2, inertia 117647.798\n",
      "Iteration  3, inertia 116885.227\n",
      "Iteration  4, inertia 115951.690\n",
      "Iteration  5, inertia 115136.843\n",
      "Iteration  6, inertia 114799.534\n",
      "Iteration  7, inertia 114619.729\n",
      "Iteration  8, inertia 114456.061\n",
      "Iteration  9, inertia 114368.486\n",
      "Iteration 10, inertia 114318.238\n",
      "Iteration 11, inertia 114281.141\n",
      "Iteration 12, inertia 114261.242\n",
      "Iteration 13, inertia 114249.458\n",
      "Iteration 14, inertia 114241.869\n",
      "Iteration 15, inertia 114235.702\n",
      "Iteration 16, inertia 114228.850\n",
      "Iteration 17, inertia 114218.270\n",
      "Iteration 18, inertia 114200.822\n",
      "Iteration 19, inertia 114178.279\n",
      "Iteration 20, inertia 114157.965\n",
      "Iteration 21, inertia 114144.964\n",
      "Iteration 22, inertia 114136.708\n",
      "Iteration 23, inertia 114130.416\n",
      "Iteration 24, inertia 114125.189\n",
      "Iteration 25, inertia 114120.984\n",
      "Iteration 26, inertia 114117.522\n",
      "Iteration 27, inertia 114114.629\n",
      "Iteration 28, inertia 114112.113\n",
      "Iteration 29, inertia 114110.050\n",
      "Iteration 30, inertia 114108.335\n",
      "Iteration 31, inertia 114106.731\n",
      "Iteration 32, inertia 114105.149\n",
      "Iteration 33, inertia 114103.380\n",
      "Iteration 34, inertia 114101.469\n",
      "Iteration 35, inertia 114099.276\n",
      "Iteration 36, inertia 114095.976\n",
      "Iteration 37, inertia 114091.707\n",
      "Iteration 38, inertia 114086.041\n",
      "Iteration 39, inertia 114076.742\n",
      "Iteration 40, inertia 114059.292\n",
      "Iteration 41, inertia 114014.754\n",
      "Iteration 42, inertia 113972.717\n",
      "Iteration 43, inertia 113957.857\n",
      "Iteration 44, inertia 113947.861\n",
      "Iteration 45, inertia 113936.520\n",
      "Iteration 46, inertia 113919.162\n",
      "Iteration 47, inertia 113875.015\n",
      "Iteration 48, inertia 113780.884\n",
      "Iteration 49, inertia 113680.983\n",
      "Iteration 50, inertia 113647.963\n",
      "Iteration 51, inertia 113639.544\n",
      "Iteration 52, inertia 113635.946\n",
      "Iteration 53, inertia 113634.012\n",
      "Iteration 54, inertia 113632.784\n",
      "Iteration 55, inertia 113631.981\n",
      "Iteration 56, inertia 113631.565\n",
      "Iteration 57, inertia 113631.301\n",
      "Iteration 58, inertia 113631.093\n",
      "Iteration 59, inertia 113630.962\n",
      "Iteration 60, inertia 113630.860\n",
      "Iteration 61, inertia 113630.788\n",
      "Iteration 62, inertia 113630.741\n",
      "Iteration 63, inertia 113630.720\n",
      "Converged at iteration 63: center shift 3.074516e-07 within tolerance 4.275357e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=15, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit our tfidf data to the kmeans model\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '10', '2016', '2017', 'accord', 'add', 'administration', 'advertisement', 'american', 'and', 'another', 'around', 'as', 'ask', 'attack', 'back', 'become', 'begin', 'believe', 'best', 'big', 'business', 'call', 'campaign', 'case', 'change', 'child', 'city', 'close', 'com', 'come', 'company', 'continue', 'could', 'country', 'court', 'day', 'de', 'deal', 'do', 'election', 'end', 'even', 'every', 'face', 'facebook', 'family', 'far', 'feel', 'find', 'first', 'follow', 'for', 'force', 'former', 'game', 'give', 'good', 'google', 'government', 'group', 'he', 'health', 'help', 'high', 'hold', 'home', 'house', 'if', 'image', 'include', 'issue', 'job', 'keep', 'know', 'la', 'last', 'later', 'law', 'le', 'lead', 'leader', 'leave', 'life', 'live', 'long', 'look', 'lot', 'main', 'man', 'many', 'market', 'may', 'mean', 'medium', 'member', 'might', 'million', 'month', 'move', 'mr', 'much', 'name', 'national', 'need', 'never', 'news', 'next', 'north', 'number', 'offer', 'office', 'official', 'old', 'on', 'open', 'part', 'party', 'pay', 'people', 'percent', 'photo', 'place', 'plan', 'play', 'point', 'police', 'post', 'power', 'president', 'public', 'put', 'question', 'read', 'really', 'release', 'report', 'republican', 'right', 'run', 'school', 'second', 'security', 'see', 'seem', 'service', 'set', 'share', 'she', 'show', 'sign', 'since', 'so', 'something', 'start', 'state', 'statement', 'still', 'story', 'support', 'system', 'talk', 'tax', 'team', 'tell', 'that', 'there', 'they', 'thing', 'think', 'this', 'three', 'to', 'today', 'top', 'trump', 'try', 'turn', 'twitter', 'two', 'united', 'us', 'use', 'video', 'want', 'washington', 'way', 'we', 'week', 'well', 'what', 'when', 'white', 'without', 'woman', 'work', 'world', 'write', 'york', 'you']\n",
      " north trump state president us\n",
      "\n",
      " image mr us people use\n",
      "\n",
      " google company use home work\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save kmeans model \n",
    "joblib.dump(km, 'model/kmeans_model.pkl')\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "labels = km.labels_\n",
    "print(terms)\n",
    "\n",
    "# order_centroids\n",
    "\n",
    "for i in range(3):\n",
    "    for ind in order_centroids[i, :5]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " north trump state president us united country official leader security could force attack report administration\n",
      "\n",
      " image mr us people use show medium first see work he could world two photo\n",
      "\n",
      " google company use home work look play well facebook service see system include still come\n",
      "\n",
      " mr main advertisement story continue read york trump sign he president you state photo try\n",
      "\n",
      " de la le advertisement 2017 google facebook twitter trump on come 10 image 2016 us\n",
      "\n",
      " police attack man report he people tell old two city accord find family video home\n",
      "\n",
      " court case state law government trump he right two president use could tell issue accord\n",
      "\n",
      " woman she tell story people work report come know write york news think and many\n",
      "\n",
      " state government attack people country president official group report party security law trump health american\n",
      "\n",
      " game play team first point run he two second three back start last best come\n",
      "\n",
      " tax trump plan republican pay house percent president state business 000 company american could government\n",
      "\n",
      " 2017 report twitter show facebook may photo video news share first post com million accord\n",
      "\n",
      " company million business market service use report work share include percent last plan we first\n",
      "\n",
      " trump president house white campaign administration republican state he news election former american washington official\n",
      "\n",
      " people and use know work think thing want way see look come life even you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare saved and loaded kmeans\n",
    "kmeans_loaded = joblib.load('model/kmeans_model.pkl')\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "order_centroids = kmeans_loaded.cluster_centers_.argsort()[:, ::-1]\n",
    "labels = kmeans_loaded.labels_\n",
    "\n",
    "# order_centroids\n",
    "\n",
    "for i in range(15):\n",
    "    for ind in order_centroids[i, :15]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small test for how we can eventually persist the cluster labels for individual articles\n",
    "# Since the labels attribute is in the order that the sparse matrix was in when it was passed in\n",
    "# We should be able just insert the label value as a dataframe column\n",
    "\n",
    "t = pd.Series(labels)\n",
    "data['cluster_label'] = t\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "X_test = tfidf.fit_transform([data.lemmatized_body[160]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features. Got 100 features, expected 200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-db99a25b3551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thefl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster_centers_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_labels_inertia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thefl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    869\u001b[0m             raise ValueError(\"Incorrect number of features. \"\n\u001b[0;32m    870\u001b[0m                              \"Got %d features, expected %d\" % (\n\u001b[1;32m--> 871\u001b[1;33m                                  n_features, expected_n_features))\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incorrect number of features. Got 100 features, expected 200"
     ]
    }
   ],
   "source": [
    "z = km.predict(X_test)\n",
    "print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
